\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage[final]{nips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
%\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{siunitx}

\title{Deep Learning Project for CSC 416}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Mitchell Anderson \\
  Computer Science Undergraduate \\
  South Dakota School of Mines and Technology\\
  Rapid City, SD 57701 \\
  \texttt{mitchell.anderson@mines.sdsmt.edu} \\\
}
%\nipsfinalcopy

\begin{document}

\maketitle

\begin{abstract}
  This paper covers the process through which a deep 
  neural network was created for the ImageNet dataset. It
  covers what was hoped to have been accomplish and the setbacks
  that were encountered.
\end{abstract}

\section{Introduction}

In the process of attempting to write the program, several consecutive
issues were encountered. The code was largely based off of a tutorial
from the TensorFlow website which covered the estimator API[1]. During
the extended week, a different approach was attempted, to see if something
functioning could quickly be put together, however, this attempt fell short
as well.

\subsection{What Went Wrong Initially}

The tutorial from the TensorFlow website introduced estimators using
the iris dataset. This utilized data from a CSV file, which it parsed
and fed into a training algorithm. The goal for this project was to
modify the TensorFlow code to read and train on images from the ImageNet
dataset. During this process, however, there were several issues encountered
to which a solution was never found.

Through the process, many of the issues were overcome, but the problem
of adapting the code to the ImageNet dataset proved more difficult than
expected. The final issue encountered which no solution was found for
was to use the data collected from the images and feed it into the
\texttt{DNNClassifier} function. To do this, the data first had to be used to
create a \texttt{feature\_column}, which was then fed into \texttt{DNNClassifier}.

It is unknown whether it was the creating a \texttt{feature\_column} step which
was never solved, or if it was feeding that information into the
\texttt{DNNClassifier} that caused the issue. It is also possible that there
was a bug elsewhere in the program which was spilling over into that
section.

When the program (which can be found in the code's repository history from
Apr 22, 2018) is run, the most recently encountered error is printed
to the screen. Given the error, it is possible for issue to have occurred
anywhere in the program. A likely location, aside from the aforementioned
areas, could be in the \texttt{train\_input\_fn} function, which was another parameter
given to \texttt{DNNClassifier}.

\subsection{What Went Wrong on the Second Attempt}

As mentioned, during the extended week for the project, a second method
was attempted to classify images from the ImageNet dataset. Again, the code
was based off a tutorial, but this time one given by Chengwei Zhang[2].
This tutorial used the TensorFlow Keras integration to create a
TensorFlow Estimator, then used that estimator to train a neural network.

Similarly to before, the code was modified to accommodate using the
ImageNet URL dataset. Once again, there were many errors that were raised
one after another, so it was unable to be completed after one short week.

If there had been enough time, the program seemed easily completable had
image files been used, rather than image URLs. It appeared fairly
straightforward how to feed image files into the program, but decoding
image files remotely from a website, then feeding that into the TensorFlow
proved to be a more difficult task than anticipated.

One final thing to note from the second attempt is that the tutorial used
a TensorFlow function called VGG16 (commented out in the source code).
However, when this was used, an exception was raised stating that 
\texttt{h5py} was required. A quick look online revealed that the most
likely solution was simply to install \texttt{h5py} using \texttt{pip}.
However, the code was being run on the Linux23 lab machine, so it could
not be installed due to privilege levels. Either being unable to use this
function or using image URLs rather than image files is likely what
caused the most recent error, displayed when the program is run.

\subsection{What Was the Goal}

As mentioned before, the goal was to modify the tutorial program
given by TensorFlow (and later given by Chengwei Zhang) to analyze
and classify images from the ImageNet dataset, rather than classifying
the iris dataset using CSV files.

Since the program was never finished, different optimizations could
not be done. Had there been an opportunity, many different hyperparameters
would have been tuned to find the most accurate result. This includes the
number of hidden layers and neurons in those layers, the activation function,
and the optimization function, among others.

As the program was never completed, the following the sections could not be
expanded upon. However, the outline of what would have been
discussed is shown below.

\section{Neural Network Architecture}

In this section, the program's deep neural network architecture would
be explained, as well as the reasons for why it was chosen. The current
architecture of the program is explained here, however, some of the aspects
would likely change should the program be completed, tested, and tweaked.

The program currently has a deep neural network, consisting of two hidden layers,
each with ten neurons. The input layer is of the shape \texttt{(150, 150, 3)}, so
it requires an image with a resolution of 150x150 where the three is the RGB values.
The activation functions for both of these layers is ReLU. If the aforementioned \texttt{VGG16} function were working, then there would be extra pre-trained 
layers given by the function which would help with the classification.

The networks optimizer is using the \texttt{RMSprop} function provided by
Keras. The learning rate is set to \num{1e-10}, as suggested by the
tutorial given by Chengwei Zhang. This model, created in Keras, is then
fed into the TensorFlow estimator framework, using the function
\texttt{model\_to\_estimator}. The input data is resized to the shape of
\texttt{(150, 150, 3)}, and the data is then fed into the estimator.

\section{Techniques Used to Optimize Results}

This section would cover what techniques would have been used
to fine tune and produce the best possible results. For example, an explanation
behind the tests performed on different activation functions and
which one was chosen to have provided the best results. How the
training set was split from the test set would also be explained here.

\section{The Results}

In this section, the results of the deep neural network would
be stated and analyzed. Including tables and visualizations of
the results and the sets used to train and test.

\section{Future Enhancements}

In this final section, the parts of the program which could have
been further improved would be discussed. Further tests could also
be discussed here.

At the moment, the improvements to be made to the program includes,
simply, to make the program run without error.

\section*{References}

\small

[1] The TensorFlow Authors\ \ (2016) {\it Premade Estimators for ML
Beginners.} https://www.tensorflow.org/

[2] Zhang, Chengwei\ \ (2017) {\it An Easy Guide to Build New TensorFlow Datasets and Estimator with Keras Model} https://www.dlology.com/

\end{document}
